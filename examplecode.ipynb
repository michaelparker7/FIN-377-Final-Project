{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL USE LIBRARY IMPORTS\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import random as rand\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of team abbvs and names\n",
    "team_abbvs = ['ATL', 'BOS', 'BRK', 'CHO', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',  'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC','SAS', 'TOR', 'UTA','WAS']\n",
    "team_names = ['Atlanta Hawks','Boston Celtics','Brooklyn Nets','Charlotte Hornets','Chicago Bulls','Cleveland Cavaliers','Dallas Mavericks','Denver Nuggets','Detroit Pistons','Golden State Warriors','Houston Rockets','Indiana Pacers','Los Angeles Clippers','Los Angeles Lakers','Memphis Grizzlies','Miami Heat','Milwaukee Bucks','Minnesota Timberwolves','New Orleans Pelicans','New York Knicks','Oklahoma City Thunder','Orlando Magic','Philadelphia 76ers','Phoenix Suns','Portland Trail Blazers','Sacramento Kings','San Antonio Spurs','Toronto Raptors','Utah Jazz','Washington Wizards']\n",
    "name_to_abbv = dict(zip(team_names,team_abbvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VH</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>A_Final_Score</th>\n",
       "      <th>ML</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>H_Final_Score</th>\n",
       "      <th>W/L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V</td>\n",
       "      <td>Washington</td>\n",
       "      <td>84</td>\n",
       "      <td>-250</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>94</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V</td>\n",
       "      <td>Boston</td>\n",
       "      <td>107</td>\n",
       "      <td>-280</td>\n",
       "      <td>Miami</td>\n",
       "      <td>120</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>99</td>\n",
       "      <td>-500</td>\n",
       "      <td>LALakers</td>\n",
       "      <td>91</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>88</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>Denver</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>84</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>V</td>\n",
       "      <td>Miami</td>\n",
       "      <td>77</td>\n",
       "      <td>-125</td>\n",
       "      <td>SanAntonio</td>\n",
       "      <td>113</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>V</td>\n",
       "      <td>Miami</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>SanAntonio</td>\n",
       "      <td>93</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>V</td>\n",
       "      <td>Miami</td>\n",
       "      <td>104</td>\n",
       "      <td>-110</td>\n",
       "      <td>SanAntonio</td>\n",
       "      <td>114</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>V</td>\n",
       "      <td>SanAntonio</td>\n",
       "      <td>100</td>\n",
       "      <td>-280</td>\n",
       "      <td>Miami</td>\n",
       "      <td>103</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>V</td>\n",
       "      <td>SanAntonio</td>\n",
       "      <td>88</td>\n",
       "      <td>-220</td>\n",
       "      <td>Miami</td>\n",
       "      <td>95</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    VH   Away_Team A_Final_Score    ML     Home_Team H_Final_Score W/L\n",
       "0     V  Washington            84  -250     Cleveland            94   W\n",
       "1     V      Boston           107  -280         Miami           120   W\n",
       "2     V      Dallas            99  -500      LALakers            91   L\n",
       "3     V     Indiana            90   100       Toronto            88   L\n",
       "4     V      Denver            75   110  Philadelphia            84   W\n",
       "...  ..         ...           ...   ...           ...           ...  ..\n",
       "1309  V       Miami            77  -125    SanAntonio           113   L\n",
       "1310  V       Miami           109   110    SanAntonio            93   W\n",
       "1311  V       Miami           104  -110    SanAntonio           114   W\n",
       "1312  V  SanAntonio           100  -280         Miami           103   W\n",
       "1313  V  SanAntonio            88  -220         Miami            95   W\n",
       "\n",
       "[1314 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# Read the Data\n",
    "url = 'https://www.sportsbookreviewsonline.com/scoresoddsarchives/nba-odds-2012-13/'\n",
    "\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url,headers=header)\n",
    "\n",
    "season_game_results = pd.read_html(r.text)[0]\n",
    "\n",
    "# Make first row Column Names\n",
    "season_game_results.columns = season_game_results.iloc[0]\n",
    "# Delete first row\n",
    "season_game_results = season_game_results[1:]\n",
    "# Drop columns\n",
    "season_game_results.drop(columns=['Date', 'Rot','1st', '2nd', '3rd', '4th', 'Open', 'Close', '2H'], inplace=True)\n",
    "# Rename Columns\n",
    "column_name_changes = {\n",
    "    'Team': 'Away_Team',\n",
    "    'Final': 'A_Final_Score'}\n",
    "season_game_results.rename(columns=column_name_changes, inplace=True)\n",
    "\n",
    "season_game_results['Home_Team'] = season_game_results.apply(lambda row: row['Away_Team'] if row['VH'] == 'H' else '', axis=1).shift(-1)\n",
    "season_game_results['H_Final_Score'] = season_game_results.apply(lambda row: row['A_Final_Score'] if row['VH'] == 'H' else '', axis=1).shift(-1)\n",
    "season_game_results['ML'] = season_game_results['ML'].shift(-1)\n",
    "season_game_results = season_game_results[~(season_game_results.index % 2 == 0)]\n",
    "season_game_results['W/L'] = season_game_results.apply(lambda row: 'W' if row['H_Final_Score'] >= row['A_Final_Score'] else 'L', axis=1)\n",
    "\n",
    "season_game_results = season_game_results.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display df\n",
    "season_game_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Players   MP  FG FGA   FG%  3P 3PA   3P%  FT FTA  ...  DRB%  TRB%  \\\n",
      "0  Team Totals  240  39  82  .476  22  49  .449  14  16  ...  87.2  56.4   \n",
      "\n",
      "   AST% STL%  BLK%  TOV%   USG%   ORtg   DRtg  BPM  \n",
      "0  69.2  6.9  13.6  10.1  100.0  131.7  108.6  NaN  \n",
      "\n",
      "[1 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "df_target = pd.DataFrame(columns=hometeam.columns)\n",
    "\n",
    "# extract last row (team data)\n",
    "new_row = hometeam.iloc[-1]\n",
    "new_row_df = new_row.to_frame().T\n",
    "\n",
    "# Optionally, reset the index if you don't want the original index\n",
    "new_row_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_target = pd.concat([df_target, new_row_df ], ignore_index=True)\n",
    "print(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team stats\n",
    "team_stats = pd.DataFrame(columns = ['Team', 'FG%', '3P%', 'FT%', 'TOVs forced',\n",
    "                                     'TOV', 'PPG', 'TS%', 'eFG%', 'TRB%', 'TOV%',\n",
    "                                     'ORtg', 'DRtg'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxscore(response):\n",
    "    \n",
    "    boxscore = pd.read_html(response)\n",
    "    # differing layouts if ot\n",
    "    num = len(boxscore)\n",
    "    num_div_two = int(num/2)\n",
    "    awayteam_basic = boxscore[0]\n",
    "    awayteam_advanced = boxscore[num_div_two -1]\n",
    "    hometeam_basic = boxscore[num_div_two]\n",
    "    hometeam_advanced = boxscore[num-1]\n",
    "    \n",
    "    awayteam = pd.merge(awayteam_basic,awayteam_advanced,left_index= True,right_index =True)\n",
    "    awayteam = awayteam.drop(5,axis = 0).drop(columns = ('Unnamed: 0_level_0_y','Starters'),axis = 1)\n",
    "    awayteam = awayteam.rename(columns={'Starters': 'Players'})\n",
    "    awayteam.columns = awayteam.columns.droplevel(0)\n",
    "    \n",
    "    hometeam = pd.merge(hometeam_basic,hometeam_advanced,left_index= True,right_index =True)\n",
    "    hometeam = hometeam.drop(5,axis = 0).drop(columns = ('Unnamed: 0_level_0_y','Starters'),axis = 1)\n",
    "    hometeam = hometeam.rename(columns={'Starters': 'Players'})\n",
    "    hometeam.columns = hometeam.columns.droplevel(0)\n",
    "\n",
    "    return awayteam, hometeam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date Start (ET)        Visitor/Neutral  PTS  \\\n",
      "0     Tue, Oct 24, 2023      7:30p     Los Angeles Lakers  107   \n",
      "1     Tue, Oct 24, 2023     10:00p           Phoenix Suns  108   \n",
      "2     Wed, Oct 25, 2023      7:00p        Houston Rockets   86   \n",
      "3     Wed, Oct 25, 2023      7:00p         Boston Celtics  108   \n",
      "4     Wed, Oct 25, 2023      7:00p     Washington Wizards  120   \n",
      "...                 ...        ...                    ...  ...   \n",
      "1111  Sun, Mar 31, 2024      7:00p       Dallas Mavericks  125   \n",
      "1112  Sun, Mar 31, 2024      7:00p          Chicago Bulls  109   \n",
      "1113  Sun, Mar 31, 2024      7:00p  Oklahoma City Thunder  113   \n",
      "1114  Sun, Mar 31, 2024      7:00p  Golden State Warriors  117   \n",
      "1115  Sun, Mar 31, 2024      9:00p              Utah Jazz  106   \n",
      "\n",
      "                Home/Neutral  PTS.1 Unnamed: 6 Unnamed: 7  Attend.  \\\n",
      "0             Denver Nuggets    119  Box Score        NaN  19842.0   \n",
      "1      Golden State Warriors    104  Box Score        NaN  18064.0   \n",
      "2              Orlando Magic    116  Box Score        NaN  18846.0   \n",
      "3            New York Knicks    104  Box Score        NaN  19812.0   \n",
      "4             Indiana Pacers    143  Box Score        NaN  16004.0   \n",
      "...                      ...    ...        ...        ...      ...   \n",
      "1111         Houston Rockets    107  Box Score        NaN  18055.0   \n",
      "1112  Minnesota Timberwolves    101  Box Score        NaN  18024.0   \n",
      "1113         New York Knicks    112  Box Score        NaN  19812.0   \n",
      "1114       San Antonio Spurs    113  Box Score        NaN  18718.0   \n",
      "1115        Sacramento Kings    127  Box Score        NaN  18332.0   \n",
      "\n",
      "                           Arena Notes  \n",
      "0                     Ball Arena   NaN  \n",
      "1                   Chase Center   NaN  \n",
      "2                     Kia Center   NaN  \n",
      "3     Madison Square Garden (IV)   NaN  \n",
      "4          Gainbridge Fieldhouse   NaN  \n",
      "...                          ...   ...  \n",
      "1111               Toyota Center   NaN  \n",
      "1112               Target Center   NaN  \n",
      "1113  Madison Square Garden (IV)   NaN  \n",
      "1114           Frost Bank Center   NaN  \n",
      "1115             Golden 1 Center   NaN  \n",
      "\n",
      "[1116 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of all months for NBA games in the season\n",
    "months = ['october', 'november', 'december', 'january', 'february', 'march']\n",
    "\n",
    "# Base URL for fetching data\n",
    "base_url = \"https://www.basketball-reference.com/leagues/NBA_2024_games-{}.html\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "full_schedule = []\n",
    "\n",
    "# Loop through each month and fetch game data\n",
    "for month in months:\n",
    "    try:\n",
    "        # Format URL for the current month\n",
    "        url = base_url.format(month)\n",
    "        \n",
    "        # Read HTML table data\n",
    "        month_schedule = pd.read_html(url)[0]  # Assumes the first table is the relevant one\n",
    "        \n",
    "        # Append the DataFrame to the full_schedule list\n",
    "        full_schedule.append(month_schedule)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {month}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "full_schedule_df = pd.concat(full_schedule, ignore_index=True)\n",
    "\n",
    "# Print or inspect the full schedule DataFrame\n",
    "print(full_schedule_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schedule_df.dtypes\n",
    "full_schedule_df['f_Date'] = pd.to_datetime(full_schedule_df['Date']).dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schedule_df['Home_abbr'] = full_schedule_df['Home/Neutral'].map(name_to_abbv)\n",
    "full_schedule_df['Away_abbr'] = full_schedule_df['Visitor/Neutral'].map(name_to_abbv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date Start (ET)        Visitor/Neutral  PTS  \\\n",
      "0     Tue, Oct 24, 2023      7:30p     Los Angeles Lakers  107   \n",
      "1     Tue, Oct 24, 2023     10:00p           Phoenix Suns  108   \n",
      "2     Wed, Oct 25, 2023      7:00p        Houston Rockets   86   \n",
      "3     Wed, Oct 25, 2023      7:00p         Boston Celtics  108   \n",
      "4     Wed, Oct 25, 2023      7:00p     Washington Wizards  120   \n",
      "...                 ...        ...                    ...  ...   \n",
      "1111  Sun, Mar 31, 2024      7:00p       Dallas Mavericks  125   \n",
      "1112  Sun, Mar 31, 2024      7:00p          Chicago Bulls  109   \n",
      "1113  Sun, Mar 31, 2024      7:00p  Oklahoma City Thunder  113   \n",
      "1114  Sun, Mar 31, 2024      7:00p  Golden State Warriors  117   \n",
      "1115  Sun, Mar 31, 2024      9:00p              Utah Jazz  106   \n",
      "\n",
      "                Home/Neutral  PTS.1 Unnamed: 6 Unnamed: 7  Attend.  \\\n",
      "0             Denver Nuggets    119  Box Score        NaN  19842.0   \n",
      "1      Golden State Warriors    104  Box Score        NaN  18064.0   \n",
      "2              Orlando Magic    116  Box Score        NaN  18846.0   \n",
      "3            New York Knicks    104  Box Score        NaN  19812.0   \n",
      "4             Indiana Pacers    143  Box Score        NaN  16004.0   \n",
      "...                      ...    ...        ...        ...      ...   \n",
      "1111         Houston Rockets    107  Box Score        NaN  18055.0   \n",
      "1112  Minnesota Timberwolves    101  Box Score        NaN  18024.0   \n",
      "1113         New York Knicks    112  Box Score        NaN  19812.0   \n",
      "1114       San Antonio Spurs    113  Box Score        NaN  18718.0   \n",
      "1115        Sacramento Kings    127  Box Score        NaN  18332.0   \n",
      "\n",
      "                           Arena Notes    f_Date Home_s Visitor_s Home_abbr  \\\n",
      "0                     Ball Arena   NaN  20231024    DEN       LAL       DEN   \n",
      "1                   Chase Center   NaN  20231024    GSW       PHO       GSW   \n",
      "2                     Kia Center   NaN  20231025    ORL       HOU       ORL   \n",
      "3     Madison Square Garden (IV)   NaN  20231025    NYK       BOS       NYK   \n",
      "4          Gainbridge Fieldhouse   NaN  20231025    IND       WAS       IND   \n",
      "...                          ...   ...       ...    ...       ...       ...   \n",
      "1111               Toyota Center   NaN  20240331    HOU       DAL       HOU   \n",
      "1112               Target Center   NaN  20240331    MIN       CHI       MIN   \n",
      "1113  Madison Square Garden (IV)   NaN  20240331    NYK       OKC       NYK   \n",
      "1114           Frost Bank Center   NaN  20240331    SAS       GSW       SAS   \n",
      "1115             Golden 1 Center   NaN  20240331    SAC       UTA       SAC   \n",
      "\n",
      "     Away_abbr  \n",
      "0          LAL  \n",
      "1          PHO  \n",
      "2          HOU  \n",
      "3          BOS  \n",
      "4          WAS  \n",
      "...        ...  \n",
      "1111       DAL  \n",
      "1112       CHI  \n",
      "1113       OKC  \n",
      "1114       GSW  \n",
      "1115       UTA  \n",
      "\n",
      "[1116 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(full_schedule_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_games_df = full_schedule_df[['f_Date', 'Home_abbr', 'Away_abbr']].rename(columns={\n",
    "    'f_Date': 'Date',\n",
    "    'Home_abbr': 'Home',\n",
    "    'Away_abbr': 'Away'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date Home Away\n",
      "0     20231024  DEN  LAL\n",
      "1     20231024  GSW  PHO\n",
      "2     20231025  ORL  HOU\n",
      "3     20231025  NYK  BOS\n",
      "4     20231025  IND  WAS\n",
      "...        ...  ...  ...\n",
      "1111  20240331  HOU  DAL\n",
      "1112  20240331  MIN  CHI\n",
      "1113  20240331  NYK  OKC\n",
      "1114  20240331  SAS  GSW\n",
      "1115  20240331  SAC  UTA\n",
      "\n",
      "[1116 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(simple_games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20231024', '20231025', '20231026', '20231027', '20231028', '20231029', '20231030']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create list of dates:\n",
    "# Define the start and end dates\n",
    "start_date = '2023-10-24'\n",
    "#testing with smaller set\n",
    "#end_date = '2023-10-31'\n",
    "end_date = '2023-10-30'\n",
    "\n",
    "# Generate the range of dates\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Convert to list\n",
    "date_list = list(date_range)\n",
    "\n",
    "# format dates:\n",
    "formatted_date_list = [date.strftime('%Y%m%d') for date in date_range]\n",
    "\n",
    "# Print the formatted list of dates\n",
    "print(formatted_date_list)\n",
    "# Print the list of dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_with_retry_after(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 429:\n",
    "        retry_after = int(response.headers.get('Retry-After', 60))  # Default to 60 seconds if header is missing\n",
    "        print(f\"Rate limit exceeded. Retrying after {retry_after} seconds...\")\n",
    "        time.sleep(retry_after)\n",
    "        return fetch_with_retry_after(url)  # Recursively retry fetching\n",
    "    response.raise_for_status()  # Raise an error for other status codes\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying after 3600 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     35\u001b[0m url_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.basketball-reference.com/boxscores/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m save_box_scores(formatted_date_list, simple_games_df, url_base)\n",
      "Cell \u001b[0;32mIn[224], line 19\u001b[0m, in \u001b[0;36msave_box_scores\u001b[0;34m(formatted_date_list, simple_games_df, url_base)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Fetch and save box scores\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m---> 19\u001b[0m     response \u001b[38;5;241m=\u001b[39m fetch_with_retry_after(formatted_url)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Save each team's box score in the specific game folder\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     away_df,home_df \u001b[38;5;241m=\u001b[39m get_boxscore(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "Cell \u001b[0;32mIn[218], line 6\u001b[0m, in \u001b[0;36mfetch_with_retry_after\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      4\u001b[0m     retry_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetry-After\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m60\u001b[39m))  \u001b[38;5;66;03m# Default to 60 seconds if header is missing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate limit exceeded. Retrying after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_after\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(retry_after)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fetch_with_retry_after(url)  \u001b[38;5;66;03m# Recursively retry fetching\u001b[39;00m\n\u001b[1;32m      8\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise an error for other status codes\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_box_scores(formatted_date_list, simple_games_df, url_base):\n",
    "    # Create a main directory to hold all data before zipping\n",
    "    main_folder = 'NBA_Box_Scores'\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "    for date in formatted_date_list:\n",
    "        games_df = simple_games_df[simple_games_df['Date'] == date]\n",
    "        for index, row in games_df.iterrows():\n",
    "            home_abbr = row['Home']\n",
    "            away_abbr = row['Away']\n",
    "            game_folder = f\"{date}/{away_abbr}@{home_abbr}\"  # Folder name format: YYYYMMDD/Away@Home\n",
    "            full_folder_path = os.path.join(main_folder, game_folder)\n",
    "            os.makedirs(full_folder_path, exist_ok=True)\n",
    "\n",
    "            # Format the URL\n",
    "            formatted_url = f\"{url_base}{date}0{home_abbr}.html\"\n",
    "            # Fetch and save box scores\n",
    "            try: \n",
    "                response = fetch_with_retry_after(formatted_url)\n",
    "                \n",
    "            # Save each team's box score in the specific game folder\n",
    "                away_df,home_df = get_boxscore(response.text)\n",
    "                away_df.to_csv(f\"{full_folder_path}/away_team.csv\", index=False)\n",
    "                home_df.to_csv(f\"{full_folder_path}/home_team.csv\", index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for URL {formatted_url}: {str(e)}\")\n",
    "            \n",
    "    # Zip the entire directory\n",
    "    with ZipFile(f\"{main_folder}.zip\", 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(main_folder):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(main_folder, '..')))\n",
    "\n",
    "# Example usage\n",
    "url_base = \"https://www.basketball-reference.com/boxscores/\"\n",
    "\n",
    "save_box_scores(formatted_date_list, simple_games_df, url_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m formatted_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m0\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(url_base, date, home_abbr)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Fetch the box score data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m awayteam, hometeam \u001b[38;5;241m=\u001b[39m get_boxscore(formatted_url)  \u001b[38;5;66;03m# Assuming this function returns two DataFrames\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Process both teams\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team_df \u001b[38;5;129;01min\u001b[39;00m [awayteam, hometeam]:\n",
      "Cell \u001b[0;32mIn[173], line 2\u001b[0m, in \u001b[0;36mget_boxscore\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_boxscore\u001b[39m(url):\n\u001b[0;32m----> 2\u001b[0m     boxscore \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(url)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# differing layouts if ot\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(boxscore)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1230\u001b[0m     [\n\u001b[1;32m   1231\u001b[0m         is_file_like(io),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     ]\n\u001b[1;32m   1236\u001b[0m ):\n\u001b[1;32m   1237\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1246\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[1;32m   1247\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[1;32m   1248\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[1;32m   1249\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   1250\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   1251\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[1;32m   1252\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m   1253\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[1;32m   1254\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1255\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1256\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1257\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[1;32m   1258\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[1;32m   1259\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[1;32m   1260\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[1;32m   1261\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[1;32m   1262\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1263\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   1264\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:988\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[1;32m    978\u001b[0m     io,\n\u001b[1;32m    979\u001b[0m     compiled_match,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    984\u001b[0m     storage_options,\n\u001b[1;32m    985\u001b[0m )\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 988\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:248\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:811\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:790\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[0;32m--> 790\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options\n\u001b[1;32m    792\u001b[0m         ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    793\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f\u001b[38;5;241m.\u001b[39mhandle, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    719\u001b[0m     path_or_buf,\n\u001b[1;32m    720\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    721\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    722\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    723\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "all_players_stats = pd.DataFrame()\n",
    "\n",
    "for date in formatted_date_list:\n",
    "    games_df = simple_games_df[simple_games_df['Date'] == date]\n",
    "    for index, row in games_df.iterrows():\n",
    "        # Format the URL with the current game's home team abbreviation\n",
    "        home_abbr = row['Home']\n",
    "        formatted_url = \"{}{}0{}.html\".format(url_base, date, home_abbr)\n",
    "\n",
    "        # Fetch the box score data\n",
    "        awayteam, hometeam = get_boxscore(formatted_url)  # Assuming this function returns two DataFrames\n",
    "\n",
    "        # Process both teams\n",
    "        for team_df in [awayteam, hometeam]:\n",
    "            team_df['Date'] = date  # Add date to track games\n",
    "            team_df['Games Played'] = 1  # Initialize games played\n",
    "\n",
    "            # Update player stats in the master DataFrame\n",
    "            for i, player_row in team_df.iterrows():\n",
    "                player_name = player_row['Players']\n",
    "                \n",
    "                if player_name in all_players_stats.index:\n",
    "                    # Player exists, update their stats\n",
    "                    player_stats = all_players_stats.loc[player_name]\n",
    "                    new_games_played = player_stats['Games Played'] + 1\n",
    "                    \n",
    "                    # Calculate new averages for each stat\n",
    "                    for col in player_stats.index:\n",
    "                        if col not in ['Players', 'Date', 'Games Played']:\n",
    "                            all_players_stats.at[player_name, col] = (player_stats[col] * player_stats['Games Played'] + player_row[col]) / new_games_played\n",
    "                    \n",
    "                    # Update games played\n",
    "                    all_players_stats.at[player_name, 'Games Played'] = new_games_played\n",
    "                else:\n",
    "                    # New player, add to DataFrame\n",
    "                    player_row = player_row.to_frame().T  # Transpose to convert Series to DataFrame\n",
    "                    all_players_stats = pd.concat([all_players_stats, player_row], axis=0)\n",
    "\n",
    "# Output the updated stats DataFrame\n",
    "print(all_players_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for zips\n",
    "def update_team_stats_from_zip(zip_path):\n",
    "    # DataFrame to hold all team stats\n",
    "    all_teams_stats = pd.DataFrame()\n",
    "\n",
    "    # Open the zip file\n",
    "    with ZipFile(zip_path, 'r') as zipf:\n",
    "        # List all CSV files (assuming all box scores are stored as CSVs)\n",
    "        boxscore_files = [file for file in zipf.namelist() if file.endswith('.csv')]\n",
    "\n",
    "        # Process each CSV file\n",
    "        for file_path in boxscore_files:\n",
    "            # Extract data from the CSV file\n",
    "            with zipf.open(file_path) as file:\n",
    "                df = pd.read_csv(file)\n",
    "                \n",
    "                # Get the last row which represents team stats\n",
    "                team_stats_row = df.iloc[-1]  # Access the last row directly\n",
    "                \n",
    "                team_name = team_stats_row['Team']\n",
    "                if team_name in all_teams_stats.index:\n",
    "                    # Update existing team stats and calculate new averages\n",
    "                    update_running_averages(all_teams_stats, team_name, team_stats_row)\n",
    "                else:\n",
    "                    # Add new team\n",
    "                    all_teams_stats = add_new_team(all_teams_stats, team_stats_row)\n",
    "\n",
    "    return all_teams_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update to change from zips\n",
    "## for file names\n",
    "def update_team_from_boxscore(data,date, away, home ): # path is  NBA_Box_Scores/date/away@home\n",
    "    #data = pd.DataFrame()\n",
    "    base_directory = \"NBA_Box_Scores\"\n",
    "    directory_path = f\"{base_directory}/{date}/{away}@{home}\"\n",
    "    boxscore_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    for file_name in boxscore_files:\n",
    "        if file_name == \"away_team.csv\":\n",
    "            team_name = away\n",
    "        elif file_name == \"home_team.csv\":\n",
    "            team_name = home\n",
    "        else:\n",
    "            print(\"error no csv found\")\n",
    "            continue\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        team_stats_row = df.iloc[-1]\n",
    "        # convert objects into floats\n",
    "        #numeric_columns = team_stats_row.drop(['Players'])  # Assuming 'Team' and 'Games Played' are not to be converted\n",
    "        #team_stats_row[numeric_columns.index] = numeric_columns.astype(float)\n",
    "        \n",
    "        if team_name in data.index:\n",
    "            data = update_running_team_averages(data, team_name, team_stats_row)\n",
    "        else:\n",
    "            # Add new team\n",
    "            data = add_new_team(data,team_name, team_stats_row)\n",
    "\n",
    "    return data\n",
    "    \n",
    "        \n",
    "\n",
    "def update_running_team_averages(data, team_name, team_stats_row):\n",
    "    \"\"\"Update team stats and calculate running averages.\"\"\"\n",
    "    existing_stats = data.loc[team_name]\n",
    "    games_played = existing_stats['Games Played'] + 1\n",
    "    for col in team_stats_row.index:\n",
    "        new_value = pd.to_numeric(team_stats_row[col], errors='coerce')\n",
    "        old_avg = pd.to_numeric(existing_stats[col], errors='coerce')\n",
    "        if pd.notna(new_value) and pd.notna(old_avg):\n",
    "            new_avg = ((old_avg * (games_played - 1)) + new_value) / games_played\n",
    "            data.at[team_name, col] = new_avg\n",
    "    data.at[team_name, 'Games Played'] = games_played\n",
    "    return data\n",
    "\n",
    "def add_new_team(data, team_name, team_stats_row):\n",
    "    \"\"\"Add a new team to the DataFrame.\"\"\"\n",
    "    team_stats_row['Games Played'] = 1  # Initialize games played\n",
    "    team_name = [team_name]\n",
    "    team_stats_df = pd.DataFrame([team_stats_row], index = team_name)\n",
    "    data = pd.concat([data, team_stats_df])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## creates cumul team stats for a date\n",
    "all_team_stats = pd.DataFrame()\n",
    "for date in formatted_date_list:\n",
    "    games_df = simple_games_df[simple_games_df['Date'] == date]\n",
    "    for index, row in games_df.iterrows():\n",
    "        # Format the URL with the current game's home team abbreviation\n",
    "        home_abbr = row['Home']\n",
    "        away_abbr = row['Away']\n",
    "\n",
    "        all_team_stats = update_team_from_boxscore(all_team_stats,date,away_abbr,home_abbr)\n",
    "#print(all_team_stats)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of null and unnessary values\n",
    "def clean_team_stats(data):\n",
    "    new = data.drop(['Players','MP','AST','+/-','MP.1','AST%','BPM'],axis = 1, inplace = True)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devin Booker\n",
      "played\n",
      "Kevin Durant\n",
      "played\n",
      "Josh Okogie\n",
      "played\n",
      "Jusuf NurkiÄ‡\n",
      "played\n",
      "Grayson Allen\n",
      "played\n",
      "Eric Gordon\n",
      "played\n",
      "Drew Eubanks\n",
      "played\n",
      "Yuta Watanabe\n",
      "played\n",
      "Jordan Goodwin\n",
      "played\n",
      "Nassir Little\n",
      "played\n",
      "Udoka Azubuike\n",
      "fail\n",
      "Keita Bates-Diop\n",
      "fail\n",
      "Bol Bol\n",
      "fail\n",
      "Saben Lee\n",
      "fail\n",
      "Chimezie Metu\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NBA_Box_Scores/20231024/PHO@GSW/away_team.csv\")\n",
    "player_rows = df.iloc[:-1]\n",
    "        # convert objects into floats\n",
    "#print(player_rows)\n",
    "\n",
    "player_names = player_rows['Players'].tolist()\n",
    "for i, player_row in player_rows.iterrows():\n",
    "    player = player_row['Players']\n",
    "    player_stats_row = player_rows.iloc[i]\n",
    "    print(player)\n",
    "    #print(player_stats_row)\n",
    "    new_value = pd.to_numeric(player_stats_row['FG'], errors='coerce')\n",
    "    if pd.notna(new_value):\n",
    "        print(\"played\")\n",
    "    else: \n",
    "        print(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update to change from zips\n",
    "## for file names\n",
    "def update_player_from_boxscore(data, date, away, home ): # path is  NBA_Box_Scores/date/away@home\n",
    "    #data = pd.DataFrame()\n",
    "    base_directory = \"NBA_Box_Scores\"\n",
    "    directory_path = f\"{base_directory}/{date}/{away}@{home}\"\n",
    "    boxscore_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    for file_name in boxscore_files\n",
    "    \n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        player_rows = df.iloc[:-1]\n",
    "\n",
    "        player_names = player_rows['Players'].tolist()\n",
    "        for player in player_names:\n",
    "            player = player_row['Players']\n",
    "            player_stats_row = player_rows.iloc[i]\n",
    "            if player in data.index:\n",
    "            data = update_running_player_averages(data, player_name, player_stats_row)\n",
    "        else:\n",
    "            # Add new team\n",
    "            data = add_new_player(data,player_name, player_stats_row)\n",
    "\n",
    "    return data\n",
    "    \n",
    "        \n",
    "\n",
    "def update_running_player_averages(data, player_name, player_stats_row):\n",
    "    \"\"\"Update team stats and calculate running averages.\"\"\"\n",
    "    existing_stats = data.loc[player_name]\n",
    "    games_played = existing_stats['Games Played'] + 1\n",
    "    for col in player_stats_row.index:\n",
    "        new_value = pd.to_numeric(player_stats_row[col], errors='coerce')\n",
    "        old_avg = pd.to_numeric(player_stats[col], errors='coerce')\n",
    "        if pd.notna(new_value) and pd.notna(old_avg):\n",
    "            new_avg = ((old_avg * (games_played - 1)) + new_value) / games_played\n",
    "            data.at[player_name, col] = new_avg\n",
    "    data.at[player_name, 'Games Played'] = games_played\n",
    "    return data\n",
    "\n",
    "def add_new_player(data, player_name, player_stats_row):\n",
    "    \"\"\"Add a new team to the DataFrame.\"\"\"\n",
    "    player_stats_row['Games Played'] = 1  # Initialize games played\n",
    "    player_name = [player_name]\n",
    "    player_stats_df = pd.DataFrame([player_stats_row], index = player_name)\n",
    "    data = pd.concat([data, player_stats_df])\n",
    "    return data\n",
    "\n",
    "def ifplayed(player_stats_row):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates cumul team stats for a date\n",
    "all_team_stats = pd.DataFrame()\n",
    "for date in formatted_date_list:\n",
    "    games_df = simple_games_df[simple_games_df['Date'] == date]\n",
    "    for index, row in games_df.iterrows():\n",
    "        # Format the URL with the current game's home team abbreviation\n",
    "        home_abbr = row['Home']\n",
    "        away_abbr = row['Away']\n",
    "\n",
    "        all_team_stats = update_team_from_boxscore(all_team_stats,date,away_abbr,home_abbr)\n",
    "#print(all_team_stats)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd27cc09c374300ee72894d4f68787fc0c6f29f2b20f7db675d2972694fa9e30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
